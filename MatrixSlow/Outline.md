
### 一、模型与计算图

（本章为机器学习模型和计算图的概述，以及如何用计算图实现模型。）

- 1.1 机器学习与模型
- 1.2 用计算图实现模型
- 1.3 计算图的实现


### 二、最简单的神经网络：逻辑回归

（本章从神经网络的视角介绍二分类/多分类逻辑回归，讲解其原理与应用，以及如何用计算图表示逻辑回归。）

- 2.1 逻辑回归模型的结构
- 2.2 多分类逻辑归回模型
- 2.3 用计算图搭建多分类逻辑回归


### 三、计算图如何学习
（本章从如何训练逻辑回归引入计算图的自动求导、梯度下降以及几种优化算法的变体。）

- 3.1 自动求导的原理
- 3.2 自动求导的实现
- 3.3 实例：训练逻辑回归模型


### 四、合作的神经元：多层全连接神经网络
（多分类逻辑回归相当于单层神经网络，本章从单层进入多层，讲解多层全连接神经网络的原理和应用，以及如何用计算图搭建。）

- 4.1 全连接层
- 4.2 搭建多层全连接神经网络
- 4.3 实例：鸟类生态类群分类


### 五、花式连接：几种非全连接神经网络
（本章从全连接到非全连接，展现计算图的强大表达能力，介绍Wide & Deep、FM、FFM、DeepFM模型。）

- 5.1 CTR预估问题
- 5.2 Wide & Deep问题
- 5.3 因子分解机FM
- 5.4 域感知因子分解机FFM
- 5.5 深度因子分解机DeepFM


### 六、深度学习：卷积神经网络（CNN）
（本章介绍CNN的原理以及应用，介绍如何用计算图搭建CNN。）

- 6.1 卷积神经网络的原理
- 6.2 构造卷积层
- 6.3 构造池化层
- 6.4 搭建卷积神经网络
- 6.5 实例：运用CNN进行MNIST手写数字识别


### 七、时间序列：循环神经网络（RNN）
（本章介绍RNN的原理以及应用，介绍如何用计算图搭建RNN。）

- 7.1 递归神经网络的原理
- 7.2 编码器-解码器
- 7.3 搭建递归神经网络
- 7.4 实例：运用RNN进行时间序列预测


### 八、训练与评估
（介绍一个典型的训练器（Trainer）应该完成什么样的工作：例如Batch、Epoch、训练集\测试集、模型的评估等。）

- 8.1 基本概念和经典训练流程
- 8.2 训练器的实现
- 8.3 模型评估指标及实现


### 九、模型保存与载入
（本章介绍模型的保存与载入。）

- 9.1 模型结构和权重
- 9.2 模型序列化和保存
- 9.3 模型载入和使用


### 十、预测、部署与服务
（本章介绍介绍训练完成的模型的应用：预测以及模型的部署。）

- 10.1 模型预测流程和方式
- 10.2 Protobuf和GRPC
- 10.3 一个通用模型服务框架的实现


### 十一、提高效率：分布式并发训练
（本章讲解几种并发分布式训练算法的原理与实现。）

- 11.1 分布式训练的基本概念
- 11.2 PS架构的分布式训练和实现
- 11.3 Ring All-Reduce架构的分布式训练和实现

### 十二、静态图与动态图
- 12.1 静态图与动态图
- 12.2 图优化
- 12.3 图切割

### 十三、成为一个真正的机器学习框架
- 13.1 更高的执行效率
- 13.2 异构平台和硬件加速
- 13.3 数据读取和处理

### 附录
（附录介绍本书需要的 Numpy编程基础。）


